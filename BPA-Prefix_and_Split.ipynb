{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import all necessary libraries ##\n",
    "import distance\n",
    "\n",
    "from similarity.levenshtein import Levenshtein\n",
    "levenshtein = Levenshtein()\n",
    "\n",
    "from similarity.damerau import Damerau\n",
    "damerau = Damerau()\n",
    "\n",
    "from pyjarowinkler import distance as jwdistance\n",
    "from similarity.jarowinkler import JaroWinkler\n",
    "jarowinkler = JaroWinkler()\n",
    "\n",
    "from similarity.weighted_levenshtein import WeightedLevenshtein\n",
    "from similarity.weighted_levenshtein import CharacterSubstitutionInterface\n",
    "import math\n",
    "class CharacterSubstitution(CharacterSubstitutionInterface):\n",
    "    def cost(self, c0, c1):\n",
    "        return math.inf # assign inifte weight to all substitutions\n",
    "levenshtein2 = WeightedLevenshtein(CharacterSubstitution())\n",
    "\n",
    "#########################\n",
    "\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import random \n",
    "\n",
    "#########################\n",
    "\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.algo.filtering.log.attributes import attributes_filter\n",
    "from pm4py.algo.filtering.log.variants import variants_filter\n",
    "\n",
    "\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59de572aa93e4f6dbc7b8ddddc960301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/1199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## import dataset ##\n",
    "file = \"BPIC15\"\n",
    "log = xes_importer.apply(\"../Datasets/\"+ file + \".xes\") # adjust for local file location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate mapping from activities to chars ##\n",
    "\n",
    "# extract all activities from log and convert them into list\n",
    "activities = list(attributes_filter.get_attribute_values(log, \"concept:name\").keys())\n",
    "\n",
    "transl = {} # dictionary mapping the names of the activities to chars\n",
    "for i, a in enumerate(activities):\n",
    "    transl[a] = chr(i+1)\n",
    "\n",
    "def list_to_string(trace):\n",
    "    string = \"\"\n",
    "    for e in trace:\n",
    "        string = string + transl[e] \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 strings: ['\\x01\\x02\\x03\\x04\\x05\\x06\\x07\\x08\\t\\n\\x0b\\x0c\\r\\x0e\\x0f\\x10\\x11\\x12\\x13\\x14\\x15\\x16\\x17\\x18\\x19\\x1a\\x1b\\x1c\\x1d\\x1e\\x1f !\"#$%&\\'()*+,-', '\\x06\\x07\\x08\\x02\\x03\\x04\\x05\\x01\\n\\t\\x0c\\x0b\\r\\x0e./\\x19012345678\\x0f\\x10\\x11\\x12\\x13\\x14\\x15\\x16\\x17\\x18#$\\x0e*)\\x1d+ \\x1b\\x1e!\\x1f%\"\\'\\x1a\\x1c-&(,', '\\x01\\x02\\x03\\x04\\x05\\x06\\x07\\x08\\t\\x0b\\x0c\\n\\r\\x0e./\\x190124356\\x0e8\\x0f\\x10\\x11\\x12\\x13\\x14\\x15\\x16\\x177\"\\x1b\\x1d\\x1c\\x1f\\x1e !\\x18\\x1a#$\\'%*+),-&(', '\\x01\\x02\\x03\\x04\\x05\\x06\\x07\\x08\\n\\x0c\\x0b\\t\\r\\x0e./\\x19102476358\\x0f\\x10\\x11\\x12\\x13\\x14\\x15\\x16\\x17\\x18\\x0e!\\x1c\\x1d\\x1e \\x1f\"\\x1b\\x1a#$%\\'+9)*(&,-', '\\x01\\x02\\x03\\x04\\x05\\x06\\x08\\t\\x0b\\n\\x0c\\r\\x19\\x0e\\x0f\\x10\\x11\\x12\\x13\\x14\\x15\\x16\\x17\\x18\\x07! \\x1a\\x1b\\x1d\\x1c\\x1f\"\\x1e#$*%\\'9+)&-(,']\n",
      "No. of strings: 1170\n"
     ]
    }
   ],
   "source": [
    "## generate list of strings for all variants ##\n",
    "\n",
    "variants = list(variants_filter.get_variants(log).keys())\n",
    "strings = [] # list of strings for each variant\n",
    "variant_to_index = {} # dicitionary to translate variant to index in list for later lookup of traces\n",
    "\n",
    "# generate strings\n",
    "for i, v in enumerate(variants):\n",
    "    strings.append(list_to_string(v.split(\",\")))\n",
    "    variant_to_index[v] = i\n",
    "\n",
    "# translation function: trace to index\n",
    "def trace_to_index(trace):\n",
    "    # convert trace to string representation of variant (concept:name separated by commas)\n",
    "    trace_string = \"\"\n",
    "    for e in trace:\n",
    "        trace_string = trace_string + e[\"concept:name\"] + \",\"\n",
    "    trace_string = trace_string[:-1] # remove last comma\n",
    "    \n",
    "    # lookup string representation of variant\n",
    "    return variant_to_index[trace_string]\n",
    "        \n",
    "print(\"First 5 strings:\", strings[:5])\n",
    "print(\"No. of strings:\", len(strings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 strings: ['\\x01\\x02\\x03\\x04\\x05\\x06\\x07\\x08\\t\\n\\x0b\\x0c\\r\\x0e\\x0f\\x10\\x11\\x12\\x13\\x14\\x15\\x16\\x17\\x18\\x19\\x1a\\x1b\\x1c\\x1d\\x1e\\x1f !\"#$%&\\'()*+,-\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00', '\\x06\\x07\\x08\\x02\\x03\\x04\\x05\\x01\\n\\t\\x0c\\x0b\\r\\x0e./\\x19012345678\\x0f\\x10\\x11\\x12\\x13\\x14\\x15\\x16\\x17\\x18#$\\x0e*)\\x1d+ \\x1b\\x1e!\\x1f%\"\\'\\x1a\\x1c-&(,\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00', '\\x01\\x02\\x03\\x04\\x05\\x06\\x07\\x08\\t\\x0b\\x0c\\n\\r\\x0e./\\x190124356\\x0e8\\x0f\\x10\\x11\\x12\\x13\\x14\\x15\\x16\\x177\"\\x1b\\x1d\\x1c\\x1f\\x1e !\\x18\\x1a#$\\'%*+),-&(\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00', '\\x01\\x02\\x03\\x04\\x05\\x06\\x07\\x08\\n\\x0c\\x0b\\t\\r\\x0e./\\x19102476358\\x0f\\x10\\x11\\x12\\x13\\x14\\x15\\x16\\x17\\x18\\x0e!\\x1c\\x1d\\x1e \\x1f\"\\x1b\\x1a#$%\\'+9)*(&,-\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00', '\\x01\\x02\\x03\\x04\\x05\\x06\\x08\\t\\x0b\\n\\x0c\\r\\x19\\x0e\\x0f\\x10\\x11\\x12\\x13\\x14\\x15\\x16\\x17\\x18\\x07! \\x1a\\x1b\\x1d\\x1c\\x1f\"\\x1e#$*%\\'9+)&-(,\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00']\n"
     ]
    }
   ],
   "source": [
    "## optional padding when using Hamming distance ##\n",
    "\n",
    "count = 0\n",
    "for s in strings:\n",
    "    if len(s) > count:\n",
    "        count = len(s)\n",
    "\n",
    "strings_pad = []\n",
    "\n",
    "for s in strings:\n",
    "    strings_pad.append(s + chr(0) * (count - len(s)))\n",
    "\n",
    "#strings = strings_pad\n",
    "\n",
    "print(\"First 5 strings:\", strings_pad[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prefix-removal + String-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 2021-01-30 20:56:42.357126\n",
      "Time needed: 0:00:01.393797\n",
      "[[0 2 1 ... 4 4 4]\n",
      " [2 0 1 ... 2 5 2]\n",
      " [1 1 0 ... 3 4 3]\n",
      " ...\n",
      " [4 2 3 ... 0 7 3]\n",
      " [4 5 4 ... 7 0 7]\n",
      " [4 2 3 ... 3 7 0]]\n"
     ]
    }
   ],
   "source": [
    "## calculation of distance matrix ##\n",
    "\n",
    "#strings = strings_pad # optional use of padded strings for Hamming\n",
    "n = len(strings)\n",
    "distMatrix = np.full((n, n), 0, dtype = np.uint8)\n",
    "\n",
    "start = datetime.now()\n",
    "print(\"Start:\", start)\n",
    "\n",
    "for i, x in enumerate(strings):\n",
    "    for j, y in enumerate(strings):\n",
    "        if j >= i: # only calculate upper right triangle of matrix\n",
    "            # prefix removal\n",
    "            prefix_len = len(os.path.commonprefix([x, y]))\n",
    "            x_pref = x[prefix_len:]\n",
    "            y_pref = y[prefix_len:]\n",
    "            \n",
    "            # string split\n",
    "            x_pref_split = round(len(x_pref)/2)\n",
    "            x_pref1 = x_pref[:x_pref_split]\n",
    "            x_pref2 = x_pref[x_pref_split:]\n",
    "            y_pref_split = round(len(y_pref)/2)\n",
    "            y_pref1 = y_pref[:y_pref_split]\n",
    "            y_pref2 = y_pref[y_pref_split:]\n",
    "            \n",
    "            #dist1 = distance.hamming(x_pref1, y_pref1) # Hamming distance\n",
    "            #dist2 = distance.hamming(x_pref2, y_pref2)\n",
    "            \n",
    "            #dist1 = levenshtein.distance(x_pref1, y_pref1) # Levenshtein v2 (faster than v1)\n",
    "            #dist2 = levenshtein.distance(x_pref2, y_pref2)\n",
    "            \n",
    "            #dist1 = levenshtein2.distance(x_pref1, y_pref1) # Levenshtein II\n",
    "            #dist2 = levenshtein2.distance(x_pref2, y_pref2)\n",
    "\n",
    "            dist1 = damerau.distance(x_pref1, y_pref1) # Damerau-Levenshtein\n",
    "            dist2 = damerau.distance(x_pref2, y_pref2)\n",
    "            \n",
    "            #dist1 = jarowinkler.similarity(x1, y_pref1) * 255 / 2 # Jaro-Winkler v2 (faster than v1)\n",
    "            #dist2 = jarowinkler.similarity(x_pref2, y_pref2) * 255 /2\n",
    "\n",
    "            dist = dist1 + dist2\n",
    "\n",
    "            distMatrix[i][j] = dist\n",
    "\n",
    "# mirror upper right triangle of matrix by adding the transposition\n",
    "distMatrix = distMatrix + distMatrix.T\n",
    "\n",
    "end = datetime.now()\n",
    "\n",
    "\n",
    "print(\"Time needed:\", end-start)\n",
    "\n",
    "np.savetxt(\"../Results/PrefixSplit/PrefixSplit-\" + file + \"-Levenshtein-\" + datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\") + \".csv\", distMatrix, fmt='%i', delimiter = \";\")\n",
    "print(distMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculation for all methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 2021-01-30 21:28:53.065319\n",
      "Time needed: 0:00:10.741896\n",
      "[[ 0 53 46 ... 24 63 48]\n",
      " [53  0 36 ... 53 60 47]\n",
      " [46 36  0 ... 55 58 37]\n",
      " ...\n",
      " [24 53 55 ...  0 64 56]\n",
      " [63 60 58 ... 64  0 61]\n",
      " [48 47 37 ... 56 61  0]]\n",
      "Start: 2021-01-30 21:29:04.116133\n",
      "Time needed: 0:05:05.962109\n",
      "[[ 0 46 36 ... 20 43 36]\n",
      " [46  0 30 ... 44 53 33]\n",
      " [36 30  0 ... 43 44 28]\n",
      " ...\n",
      " [20 44 43 ...  0 45 41]\n",
      " [43 53 44 ... 45  0 42]\n",
      " [36 33 28 ... 41 42  0]]\n",
      "Start: 2021-01-30 21:34:10.393979\n",
      "Time needed: 0:09:24.221129\n",
      "[[ 0 64 40 ... 28 55 43]\n",
      " [64  0 44 ... 60 75 49]\n",
      " [40 44  0 ... 52 65 35]\n",
      " ...\n",
      " [28 60 52 ...  0 63 47]\n",
      " [55 75 65 ... 63  0 56]\n",
      " [43 49 35 ... 47 56  0]]\n",
      "Start: 2021-01-30 21:43:34.918519\n",
      "Time needed: 0:11:47.679154\n",
      "[[ 0 46 36 ... 20 42 34]\n",
      " [46  0 29 ... 43 52 31]\n",
      " [36 29  0 ... 43 44 26]\n",
      " ...\n",
      " [20 43 43 ...  0 45 41]\n",
      " [42 52 44 ... 45  0 42]\n",
      " [34 31 26 ... 41 42  0]]\n",
      "Start: 2021-01-30 21:55:22.893837\n",
      "Time needed: 0:01:07.675914\n",
      "[[254 171 157 ... 234 187 188]\n",
      " [171 254 228 ... 171 168 207]\n",
      " [157 228 254 ... 175 177 214]\n",
      " ...\n",
      " [234 171 175 ... 254 185 191]\n",
      " [187 168 177 ... 185 254 185]\n",
      " [188 207 214 ... 191 185 254]]\n"
     ]
    }
   ],
   "source": [
    "#strings = strings_pad # optional use of padded strings for Hamming\n",
    "n = len(strings)\n",
    "\n",
    "times = np.empty(5, dtype='object')\n",
    "\n",
    "######################\n",
    "### Hamming ###\n",
    "######################\n",
    "start = datetime.now()\n",
    "distMatrix = np.full((n, n), 0, dtype = np.uint8)\n",
    "print(\"Start:\", start)\n",
    "\n",
    "for i, x in enumerate(strings_pad):\n",
    "    for j, y in enumerate(strings_pad):\n",
    "        if j >= i: # only calculate upper right triangle of matrix\n",
    "            # prefix removal\n",
    "            prefix_len = len(os.path.commonprefix([x, y]))\n",
    "            x_pref = x[prefix_len:]\n",
    "            y_pref = y[prefix_len:]\n",
    "            \n",
    "            # string split\n",
    "            x_pref_split = round(len(x_pref)/2)\n",
    "            x_pref1 = x_pref[:x_pref_split]\n",
    "            x_pref2 = x_pref[x_pref_split:]\n",
    "            y_pref_split = round(len(y_pref)/2)\n",
    "            y_pref1 = y_pref[:y_pref_split]\n",
    "            y_pref2 = y_pref[y_pref_split:]\n",
    "            \n",
    "            dist1 = distance.hamming(x_pref1, y_pref1) # Hamming distance\n",
    "            dist2 = distance.hamming(x_pref2, y_pref2)\n",
    "            \n",
    "            dist = dist1 + dist2\n",
    "\n",
    "            distMatrix[i][j] = dist\n",
    "\n",
    "# mirror upper right triangle of matrix by adding the transposition\n",
    "distMatrix = distMatrix + distMatrix.T\n",
    "\n",
    "end = datetime.now()\n",
    "\n",
    "\n",
    "print(\"Time needed:\", end-start)\n",
    "\n",
    "np.savetxt(\"../Results/PrefixSplit/PrefixSplit-\" + file + \"-Hamming-\" + datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\") + \".csv\", distMatrix, fmt='%i', delimiter = \";\")\n",
    "print(distMatrix)\n",
    "times[0] = str(end-start)\n",
    "\n",
    "######################\n",
    "### Levenshtein ###\n",
    "######################\n",
    "\n",
    "start = datetime.now()\n",
    "distMatrix = np.full((n, n), 0, dtype = np.uint8)\n",
    "\n",
    "print(\"Start:\", start)\n",
    "\n",
    "for i, x in enumerate(strings):\n",
    "    for j, y in enumerate(strings):\n",
    "        if j >= i: # only calculate upper right triangle of matrix\n",
    "            # prefix removal\n",
    "            prefix_len = len(os.path.commonprefix([x, y]))\n",
    "            x_pref = x[prefix_len:]\n",
    "            y_pref = y[prefix_len:]\n",
    "            \n",
    "            # string split\n",
    "            x_pref_split = round(len(x_pref)/2)\n",
    "            x_pref1 = x_pref[:x_pref_split]\n",
    "            x_pref2 = x_pref[x_pref_split:]\n",
    "            y_pref_split = round(len(y_pref)/2)\n",
    "            y_pref1 = y_pref[:y_pref_split]\n",
    "            y_pref2 = y_pref[y_pref_split:]\n",
    "            \n",
    "            dist1 = levenshtein.distance(x_pref1, y_pref1) # Levenshtein v2 (faster than v1)\n",
    "            dist2 = levenshtein.distance(x_pref2, y_pref2)\n",
    "\n",
    "            dist = dist1 + dist2\n",
    "\n",
    "            distMatrix[i][j] = dist\n",
    "\n",
    "# mirror upper right triangle of matrix by adding the transposition\n",
    "distMatrix = distMatrix + distMatrix.T\n",
    "\n",
    "end = datetime.now()\n",
    "\n",
    "\n",
    "print(\"Time needed:\", end-start)\n",
    "\n",
    "np.savetxt(\"../Results/PrefixSplit/PrefixSplit-\" + file + \"-Levenshtein-\" + datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\") + \".csv\", distMatrix, fmt='%i', delimiter = \";\")\n",
    "print(distMatrix)\n",
    "times[1] = str(end-start)\n",
    "\n",
    "######################\n",
    "### Levenshtein II ###\n",
    "######################\n",
    "\n",
    "start = datetime.now()\n",
    "distMatrix = np.full((n, n), 0, dtype = np.uint8)\n",
    "print(\"Start:\", start)\n",
    "\n",
    "for i, x in enumerate(strings):\n",
    "    for j, y in enumerate(strings):\n",
    "        if j >= i: # only calculate upper right triangle of matrix\n",
    "             # prefix removal\n",
    "            prefix_len = len(os.path.commonprefix([x, y]))\n",
    "            x_pref = x[prefix_len:]\n",
    "            y_pref = y[prefix_len:]\n",
    "            \n",
    "            # string split\n",
    "            x_pref_split = round(len(x_pref)/2)\n",
    "            x_pref1 = x_pref[:x_pref_split]\n",
    "            x_pref2 = x_pref[x_pref_split:]\n",
    "            y_pref_split = round(len(y_pref)/2)\n",
    "            y_pref1 = y_pref[:y_pref_split]\n",
    "            y_pref2 = y_pref[y_pref_split:]\n",
    "            \n",
    "            dist1 = levenshtein2.distance(x_pref1, y_pref1) # Levenshtein II\n",
    "            dist2 = levenshtein2.distance(x_pref2, y_pref2)\n",
    "\n",
    "            dist = dist1 + dist2\n",
    "\n",
    "            distMatrix[i][j] = dist\n",
    "\n",
    "\n",
    "# mirror upper right triangle of matrix by adding the transposition\n",
    "distMatrix = distMatrix + distMatrix.T\n",
    "\n",
    "end = datetime.now()\n",
    "\n",
    "\n",
    "print(\"Time needed:\", end-start)\n",
    "\n",
    "np.savetxt(\"../Results/PrefixSplit/PrefixSplit-\" + file + \"-Levenshtein2-\" + datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\") + \".csv\", distMatrix, fmt='%i', delimiter = \";\")\n",
    "print(distMatrix)\n",
    "times[2] = str(end-start)\n",
    "\n",
    "######################\n",
    "### Damerau-Levenshtein ###\n",
    "######################\n",
    "\n",
    "start = datetime.now()\n",
    "distMatrix = np.full((n, n), 0, dtype = np.uint8)\n",
    "print(\"Start:\", start)\n",
    "\n",
    "for i, x in enumerate(strings):\n",
    "    for j, y in enumerate(strings):\n",
    "        if j >= i: # only calculate upper right triangle of matrix\n",
    "             # prefix removal\n",
    "            prefix_len = len(os.path.commonprefix([x, y]))\n",
    "            x_pref = x[prefix_len:]\n",
    "            y_pref = y[prefix_len:]\n",
    "            \n",
    "            # string split\n",
    "            x_pref_split = round(len(x_pref)/2)\n",
    "            x_pref1 = x_pref[:x_pref_split]\n",
    "            x_pref2 = x_pref[x_pref_split:]\n",
    "            y_pref_split = round(len(y_pref)/2)\n",
    "            y_pref1 = y_pref[:y_pref_split]\n",
    "            y_pref2 = y_pref[y_pref_split:]\n",
    "            \n",
    "            dist1 = damerau.distance(x_pref1, y_pref1) # Damerau-Levenshtein\n",
    "            dist2 = damerau.distance(x_pref2, y_pref2)\n",
    "            \n",
    "            dist = dist1 + dist2\n",
    "\n",
    "            distMatrix[i][j] = dist\n",
    "\n",
    "\n",
    "# mirror upper right triangle of matrix by adding the transposition\n",
    "distMatrix = distMatrix + distMatrix.T\n",
    "\n",
    "end = datetime.now()\n",
    "\n",
    "\n",
    "print(\"Time needed:\", end-start)\n",
    "\n",
    "np.savetxt(\"../Results/PrefixSplit/PrefixSplit-\" + file + \"-Damerau-\" + datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\") + \".csv\", distMatrix, fmt='%i', delimiter = \";\")\n",
    "print(distMatrix)\n",
    "times[3] = str(end-start)\n",
    "\n",
    "######################\n",
    "### Jaro-Winkler ###\n",
    "######################\n",
    "\n",
    "start = datetime.now()\n",
    "distMatrix = np.full((n, n), 0, dtype = np.uint8)\n",
    "print(\"Start:\", start)\n",
    "\n",
    "for i, x in enumerate(strings):\n",
    "    for j, y in enumerate(strings):\n",
    "        if j >= i: # only calculate upper right triangle of matrix\n",
    "            # prefix removal\n",
    "            prefix_len = len(os.path.commonprefix([x, y]))\n",
    "            x_pref = x[prefix_len:]\n",
    "            y_pref = y[prefix_len:]\n",
    "            \n",
    "            # string split\n",
    "            x_pref_split = round(len(x_pref)/2)\n",
    "            x_pref1 = x_pref[:x_pref_split]\n",
    "            x_pref2 = x_pref[x_pref_split:]\n",
    "            y_pref_split = round(len(y_pref)/2)\n",
    "            y_pref1 = y_pref[:y_pref_split]\n",
    "            y_pref2 = y_pref[y_pref_split:]\n",
    "            \n",
    "            dist1 = jarowinkler.similarity(x_pref1, y_pref1) * 255 / 2 # Jaro-Winkler v2 (faster than v1)\n",
    "            dist2 = jarowinkler.similarity(x_pref2, y_pref2) * 255 /2\n",
    "\n",
    "            dist = dist1 + dist2\n",
    "\n",
    "            distMatrix[i][j] = dist\n",
    "\n",
    "            distMatrix[i][j] = dist\n",
    "\n",
    "# mirror upper right triangle of matrix by adding the transposition\n",
    "distMatrix = distMatrix + distMatrix.T\n",
    "\n",
    "end = datetime.now()\n",
    "\n",
    "\n",
    "print(\"Time needed:\", end-start)\n",
    "\n",
    "np.savetxt(\"../Results/PrefixSplit/PrefixSplit-\" + file + \"-JaroWinkler-\" + datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\") + \".csv\", distMatrix, fmt='%i', delimiter = \";\")\n",
    "print(distMatrix)\n",
    "times[4] = str(end-start)\n",
    "\n",
    "\n",
    "\n",
    "###################\n",
    "### End ###\n",
    "###################\n",
    "\n",
    "np.savetxt(\"../Results/PrefixSplit/PrefixSplit-\" + file + \"-times-\" + datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\") + \".csv\", times, fmt=\"%s\", delimiter = \";\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
